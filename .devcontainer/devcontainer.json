{
	"name": "Dynamic LoRA vLLM Dev",
	"dockerFile": "Dockerfile",
	"context": "..",
	"hostRequirements": {
		"gpu": "optional"
	},
	"runArgs": [
		"--gpus=all",
		"--ipc=host",
		"--ulimit", "memlock=-1",
		"--ulimit", "stack=67108864"
	],
	"workspaceFolder": "/workspace",
	"workspaceMount": "source=${localWorkspaceFolder},target=/workspace,type=bind,consistency=cached",
	"features": {
		"ghcr.io/devcontainers/features/docker-in-docker:2": { "moby": false }
	},
	"containerEnv": {
		"PYTHONPATH": "/workspace/src",
		"HF_HOME": "/workspace/.cache/huggingface",
		"CACHE_DIR": "/workspace/.cache/huggingface"
	},
	"customizations": {
		"vscode": {
			"extensions": [
				"ms-python.python",
				"ms-python.vscode-pylance",
				"ms-python.black-formatter",
				"ms-toolsai.jupyter",
				"GitHub.copilot"
			],
			"settings": {
				"python.defaultInterpreterPath": "/usr/bin/python3",
				"python.formatting.provider": "black",
				"python.linting.enabled": true,
				"python.linting.flake8Enabled": true
			}
		}
	},
	"postCreateCommand": "bash ./.devcontainer/post-create.sh"
}
